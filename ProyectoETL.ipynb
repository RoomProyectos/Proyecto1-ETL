{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto ETL\n",
    "#### Grupo 1:  Gledson - Eva - Sara - Rubén - Luis Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - - Importación de módulos y librerías - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "import os\n",
    "import locale\n",
    "\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "#  Se establece la configuración regional\n",
    "configuracion_local = locale.setlocale(locale.LC_ALL, (\"es_ES\", \"UTF-8\"))\n",
    "\n",
    "# Se toma el TOKEN de identificación para AirTable\n",
    "TOKEN =  os.getenv(\"AIRTABLE_TOKEN\")\n",
    "\n",
    "# Definir la base de AirTable donde se subirán los datos\n",
    "BASE_ID = \"\"\n",
    "\n",
    "BASE_ID = \"appOnz4LtIdKAOYfo\"\n",
    "\n",
    "print (f\"Se establece la configuración regional a {configuracion_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de datos\n",
    "\n",
    "Se definen las funciónes auxiliares para la extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal de extracción de datos\n",
    "def extrae_datos_meneos (lista_meneos, año_busqueda):\n",
    "    datos = []\n",
    "    continuar = True\n",
    "    for meneo in lista_meneos:\n",
    "        dicc_aux = {}\n",
    "        \n",
    "        # Se obtiene en primer lugar el año\n",
    "        try:\n",
    "            fecha_pub = meneo.find(\"div\", class_=\"news-submitted\").find_all(\"span\", class_=\"ts\")[1].text.split(\" \")[0]\n",
    "            año = datetime.strptime(fecha_pub,\"%d/%m/%Y\").year if len(fecha_pub) > 5 else 2024\n",
    "        except:\n",
    "            año = False\n",
    "        \n",
    "        # Si el año detectado es igual que el año buscado, se continúa con la importación\n",
    "        if año == año_busqueda:\n",
    "            ###################################    Titular    ####################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Titular\"] = meneo.find(\"h2\").text.replace(\"\\n\", \" \").strip()\n",
    "            except:\n",
    "                dicc_aux[\"Titular\"] = np.nan\n",
    "\n",
    "            ###################################    Entradilla    ###################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Entradilla\"] = meneo.find(\"div\", class_=\"news-content\").text.replace(\"\\n\", \" \").strip()\n",
    "            except:\n",
    "                dicc_aux[\"Entradilla\"] = np.nan\n",
    "                \n",
    "            ###################################   Comunidad (Temática) ############################################################\n",
    "            try:\n",
    "                dicc_aux[\"Comunidad\"] = meneo.find(\"a\", class_=\"subname\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Comunidad\"] = np.nan\n",
    "\n",
    "            ###################################    Usuario  ######################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Usuario\"] = meneo.find(\"div\", class_=\"news-submitted\").find(\"img\")[\"alt\"].strip()\n",
    "            except:\n",
    "                dicc_aux[\"Usuario\"] = np.nan\n",
    "\n",
    "            ###################################    Medio    ######################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Medio\"] = meneo.find(\"span\", class_=\"showmytitle\").text.strip()\n",
    "            except:            \n",
    "                dicc_aux[\"Medio\"] = \"meneame.net\"\n",
    "\n",
    "            ###################################    URL    ######################################################################\n",
    "            try:\n",
    "                dicc_aux[\"URL\"] = \"https://www.meneame.net\" + meneo.find(\"a\", class_=\"comments\")[\"href\"].strip()\n",
    "            except:            \n",
    "                dicc_aux[\"URL\"] = np.nan\n",
    "\n",
    "            ###################################    Fechas    ######################################################################    \n",
    "            try:\n",
    "                fechas = meneo.find(\"div\", class_=\"news-submitted\").find_all(\"span\", class_=\"ts\")\n",
    "                dicc_aux[\"Enviado\"] = fechas[0].text.strip()\n",
    "                dicc_aux[\"Publicado\"] = fechas[1].text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Enviado\"] = np.nan\n",
    "                dicc_aux[\"Publicado\"] = np.nan\n",
    "\n",
    "            ###################################    Meneos    ######################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Meneos\"] = meneo.find(\"div\", class_=\"votes\").find(\"a\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Meneos\"] = np.nan\n",
    "\n",
    "            ###################################    Click    ######################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Clicks\"] = meneo.find(\"div\", class_=\"clics\").find(\"span\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Clicks\"] = np.nan\n",
    "\n",
    "            ###################################    Positivos    ###################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Positivos\"] = meneo.find(\"span\", class_=\"positive-vote-number\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Positivos\"] = np.nan\n",
    "\n",
    "            ###################################    Votos Anónimos    ##############################################################\n",
    "            try:\n",
    "                dicc_aux[\"Anonimos\"] = meneo.find(\"span\", class_=\"anonymous-vote-number\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Anonimos\"] = np.nan\n",
    "\n",
    "            ###################################    Votos Negativos    ##############################################################\n",
    "            try:\n",
    "                dicc_aux[\"Negativos\"] = meneo.find(\"span\", class_=\"negative-vote-number\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Negativos\"] = np.nan\n",
    "\n",
    "            ###################################    Número comentarios    ###########################################################\n",
    "            try:\n",
    "                dicc_aux[\"Comentarios\"] = meneo.find(\"a\", class_=\"comments\")[\"data-comments-number\"].strip()\n",
    "            except:\n",
    "                dicc_aux[\"Comentarios\"] = np.nan\n",
    "\n",
    "            ###################################    Karma    ########################################################################\n",
    "            try:\n",
    "                dicc_aux[\"Karma\"] = meneo.find(\"span\", class_=\"karma-number\").text.strip()\n",
    "            except:\n",
    "                dicc_aux[\"Karma\"] = np.nan\n",
    "\n",
    "            datos.append(dicc_aux)\n",
    "\n",
    "        # Si se ha terminado el año buscado se detendrá la importación\n",
    "        elif año < año_busqueda:\n",
    "            continuar = False\n",
    "\n",
    "    return [datos, continuar]\n",
    "\n",
    "# Función para el cálculo de la pagina de inicio de extracción de datos del año elegido\n",
    "def busca_pagina_inicio (año_elegido, total_paginas):\n",
    "    # Se define un diccionario con las páginas de fin e inicio de cada año (obtenido manualmente)\n",
    "    num_pagina_año = {\"2005\": [10906,10878], \"2006\" : [10878,10442], \"2007\" : [10442,9759], \"2008\" : [9759,8981],\n",
    "                    \"2009\" : [8981,8196], \"2010\" : [8196,7499], \"2011\" : [7499,6782], \"2012\" : [6782,6149],\n",
    "                    \"2013\" : [6149,5623], \"2014\" : [5623,5101], \"2015\" : [5101,4609], \"2016\" : [4609,4214],\n",
    "                    \"2017\" : [4214,3774], \"2018\" : [3774,3230], \"2019\" : [3230,2733], \"2020\" : [2733,2058],\n",
    "                    \"2021\" : [2058,1409], \"2022\" : [1409,740], \"2023\" : [740,139]}\n",
    "\n",
    "    lista_a = []\n",
    "    for i in num_pagina_año.keys():\n",
    "        # Se obtiene el número de páginas de cada año, este número es invariable ya que no pueden añadirse noticias a un año ya pasado\n",
    "        lista_a.append([i,num_pagina_año[i][0] - num_pagina_año[i][1]])\n",
    "\n",
    "    # Se crea un DataFrame con esta información\n",
    "    df_pags_año = pd.DataFrame(columns=[\"año\", \"cantidad\"], data=lista_a)\n",
    "    df_pags_año.set_index(\"año\", inplace=True)\n",
    "\n",
    "    # Se añade la columna de acumulado para conocer el total de páginas a recorrer hasta cada año    \n",
    "    df_pags_año[\"acumulado\"] = df_pags_año[\"cantidad\"].cumsum()\n",
    "\n",
    "    # Con el total de páginas y el acumulado se calula la página de inicio \n",
    "    df_pags_año[\"pag_inicio\"] = total_paginas - df_pags_año[\"acumulado\"]\n",
    "\n",
    "    # Se retorna la página de inicio para el año elegido con un margen de seguridad de 1 página\n",
    "    return df_pags_año.loc[str(año_elegido),\"pag_inicio\"]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bucle para el Web Scrapping  ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BASE = \"https://old.meneame.net/\"\n",
    "\n",
    "lista_aux = []\n",
    "contador_paginas = 0\n",
    "continuar_ejecucion = True\n",
    "\n",
    "# Se solicita el año para la extracción de datos\n",
    "try:\n",
    "    año = int(input(f\"Introducir un año entre 2006 y {datetime.now().year-1}\"))\n",
    "    if año not in range(2006,datetime.now().year):\n",
    "        año = datetime.now().year-1\n",
    "        print(\"-\"*73)      \n",
    "        print(f\" Año fuera de rango, se toma por defecto el último año finalizado ({año})\")\n",
    "        print(\"-\"*73)\n",
    "    else:\n",
    "        print(\"-\"*34)\n",
    "        print(f\" Extracción de datos del año {año}\")\n",
    "        print(\"-\"*34)\n",
    "except:\n",
    "    año = datetime.now().year-1\n",
    "    print(\"-\"*69)\n",
    "    print(f\" Año incorrecto, se toma por defecto el último año finalizado ({año})\")\n",
    "    print(\"-\"*69)\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "browser.get(f\"{URL_BASE}\")\n",
    "\n",
    "# Se obtiene el número total de páginas de noticias y se calcula la página de inicio para el año elegido\n",
    "total_paginas = int(BeautifulSoup(browser.page_source, \"html.parser\").find(\"div\", class_=\"pages\").find_all(\"a\")[-2].text)\n",
    "pagina = busca_pagina_inicio(año, total_paginas)\n",
    "\n",
    "contador_pruebas = 0\n",
    "\n",
    "try:\n",
    "    while contador_pruebas < 10 and continuar_ejecucion == True:\n",
    "        try:\n",
    "            # Se solicita al navegador la apertura de la URL de la página\n",
    "            browser.get(f\"{URL_BASE}?page={pagina}\")\n",
    "\n",
    "            # Se obtiene el BeautifulSoup a partir del código fuente de la página\n",
    "            Soup_pagina_meneos = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "            # Se extrae el listado de noticias\n",
    "            lista_meneos = Soup_pagina_meneos.find_all(\"div\", class_=\"news-summary\")\n",
    "\n",
    "            # Se analiza el listado con la función de extracción\n",
    "            resultado = extrae_datos_meneos(lista_meneos, año)\n",
    "            \n",
    "            # Se añaden los resultados de la extracción a una lista\n",
    "            lista_aux.extend(resultado[0])\n",
    "\n",
    "            # Se almacena el dato para la parada del bucle\n",
    "            continuar_ejecucion = resultado[1]\n",
    "\n",
    "            # Se aumenta el contador de páginas\n",
    "            pagina += 1\n",
    "            contador_paginas += 1\n",
    "            contador_pruebas += 1\n",
    "            print(f\"Importada página {contador_paginas}  \", end=\"\\r\")\n",
    "        except:\n",
    "            print(f\"Error en página {pagina}\")\n",
    "except:\n",
    "    print(\"Ocurrido un error inesperado... ¿Estaba cargada la función?\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\" Total paginas procesadas: {contador_paginas}\")\n",
    "print(f\" Total noticias importadas: {len(lista_aux)}\")\n",
    "\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación del DataFrame con la lista de datos extraída y otro con los municipios para cruzar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipios = pd.read_csv(\"Data/Municipios.csv\", sep = \";\")\n",
    "df = pd.DataFrame(lista_aux)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMACIÓN\n",
    "\n",
    "##### Se definen funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de cálculo de franja horaria\n",
    "def franja_horaria (fecha):\n",
    "    hora = fecha.hour\n",
    "    if hora in range(6, 12):\n",
    "        return \"Mañana\"\n",
    "    elif hora in range(12, 16):\n",
    "        return \"Mediodía\"\n",
    "    elif hora in range(16, 21):\n",
    "        return \"Tarde\"\n",
    "    elif hora in range(21, 24):\n",
    "        return \"Noche\"\n",
    "    elif hora in range(0, 6):\n",
    "        return \"Madrugada\"\n",
    "    \n",
    "lista_municipios = tuple(df_municipios[\"Nombre1\"])\n",
    "lista_municipios2 = tuple(df_municipios[\"Nombre2\"])\n",
    "\n",
    "# Función de localización de municipio \n",
    "def funcion_municipios(x):    \n",
    "    municipio_encontrado = \"No encontrado\"\n",
    "    for municipio1, municipio2 in zip(lista_municipios,lista_municipios2):\n",
    "        if municipio1 in x:            \n",
    "            municipio_encontrado = municipio1\n",
    "            break\n",
    "        elif municipio2 in x:\n",
    "            municipio_encontrado = municipio1\n",
    "            break\n",
    "    \n",
    "    return municipio_encontrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se hacen cambios de tipo de dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Enviado'] = pd.to_datetime(df['Enviado'], format=\"%d/%m/%Y %H:%M\")\n",
    "df['Publicado'] = pd.to_datetime(df['Publicado'], format=\"%d/%m/%Y %H:%M\")\n",
    "df[[\"Meneos\", \"Clicks\", \"Positivos\", \"Anonimos\",\"Negativos\", \"Comentarios\", \"Karma\"]] = df[[\"Meneos\", \"Clicks\", \"Positivos\", \"Anonimos\",\"Negativos\", \"Comentarios\", \"Karma\"]].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se crean las columnas adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tiempo que le ha tomado a la noticia en ser publicada\n",
    "df['Delay'] = df['Publicado'] - df['Enviado']\n",
    "\n",
    "# Para la franja horaria, día de la semana y mes de la publicación en español (haciendo uso del locale) y trimestre\n",
    "df[\"Franja Horaria\"] = df[\"Publicado\"].apply(franja_horaria)\n",
    "df[\"Día de la Semana\"] = df[\"Publicado\"].apply(lambda x : x.strftime(\"%A\").capitalize())\n",
    "df[\"Mes\"] = df[\"Publicado\"].apply(lambda x : x.strftime(\"%B\").capitalize())\n",
    "trimestres = {1: \"1er Trimestre\", 2: \"2do Trimestre\", 3: \"3er Trimestre\", 4: \"4to Trimestre\"}\n",
    "df['Trimestre'] = df['Publicado'].dt.quarter.map(trimestres)\n",
    "\n",
    "# Para el municipio, buscamos primero por Titular\n",
    "df[\"Municipio\"] = df[\"Titular\"].apply(funcion_municipios)\n",
    "\n",
    "# Para los que no ha encontrado, buscamos también por Entradilla\n",
    "indices = df[df[\"Municipio\"] == \"No encontrado\"].index.to_list()\n",
    "for i in indices:\n",
    "    df.at[i, \"Municipio\"] = funcion_municipios(df.loc[i, \"Entradilla\"])\n",
    "\n",
    "# Para la obtención de la provincia, latitud y longitud correspondientes al municipio encontrado    \n",
    "df = df.merge(df_municipios[[\"Provincia\",\"Longitud\", \"Latitud\",\"Nombre1\"]],\n",
    "              left_on=\"Municipio\", right_on=\"Nombre1\",how=\"left\").drop(\"Nombre1\", axis=1)\n",
    "\n",
    "# Se realiza el tratamiento de NaN's y cambios de tipo para preparación para la carga\n",
    "df[\"Provincia\"] = df[\"Provincia\"].replace(np.nan, \"No encontrado\")\n",
    "df[\"Longitud\"] = df[\"Longitud\"].str.replace(\",\", \".\")\n",
    "df[\"Latitud\"] = df[\"Latitud\"].str.replace(\",\", \".\")\n",
    "df[[\"Latitud\", \"Longitud\"]] = df[[\"Latitud\", \"Longitud\"]].astype(\"float64\")\n",
    "df[\"Longitud\"] = df[\"Longitud\"].replace(np.nan, 0)\n",
    "df[\"Latitud\"] = df[\"Latitud\"].replace(np.nan, 0)\n",
    "\n",
    "df['Enviado'] = df['Enviado'].astype(\"str\")\n",
    "df['Publicado'] = df['Publicado'].astype(\"str\")\n",
    "df['Delay'] = df['Delay'].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen las variables necesarias para la API de Airtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airtable_base_url = \"https://api.airtable.com/v0\"\n",
    "\n",
    "# Headers\n",
    "headers = {\"Authorization\" : f\"Bearer {TOKEN}\",\n",
    "           \"Content-Type\"  : \"application/json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  JSON de creación de tabla\n",
    "\n",
    "Especifica los campos de la tabla, su tipo y el nombre de la tabla incluyendo el año elegido en la extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_columnas = {\"name\" : f\"Meneame_{año}\",\n",
    "        \"description\" : f\"Listado de meneos de la portada general de {año}\",\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\" : \"Titular\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Entradilla\",\n",
    "                \"type\" : \"multilineText\"\n",
    "            },            \n",
    "            {\n",
    "                \"name\" : \"Comunidad\",\n",
    "                \"type\" : \"singleSelect\",\n",
    "                \"options\" : {\n",
    "                    \"choices\":[{                        \n",
    "                        \"name\" : \"politica\"\n",
    "                    },\n",
    "                    {                        \n",
    "                        \"name\" : \"ciencia\"\n",
    "                    }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Usuario\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Medio\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"URL\",\n",
    "                \"type\" : \"url\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Enviado\",\n",
    "                \"type\" : \"dateTime\",\n",
    "                \"options\": {\n",
    "                    \"timeZone\" : \"Europe/Madrid\",\n",
    "                    \"dateFormat\" : {\n",
    "                        \"format\" : \"YYYY-MM-DD\",\n",
    "                        \"name\": \"iso\"\n",
    "                    },\n",
    "                    \"timeFormat\" : {\n",
    "                        \"format\": \"HH:mm\",\n",
    "                        \"name\": \"24hour\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Publicado\",\n",
    "                \"type\" : \"dateTime\",\n",
    "                \"options\": {\n",
    "                    \"timeZone\" : \"Europe/Madrid\",\n",
    "                    \"dateFormat\" : {\n",
    "                        \"format\" : \"YYYY-MM-DD\",\n",
    "                        \"name\": \"iso\"\n",
    "                    },\n",
    "                    \"timeFormat\" : {\n",
    "                        \"format\": \"HH:mm\",\n",
    "                        \"name\": \"24hour\"\n",
    "                    }\n",
    "                }\n",
    "            },            \n",
    "            {\n",
    "                \"name\" : \"Meneos\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Clicks\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Positivos\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Anonimos\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Negativos\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Comentarios\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"name\" : \"Karma\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 0\n",
    "                }\n",
    "            },            \n",
    "            {\n",
    "                \"name\" : \"Delay\",\n",
    "                \"type\" : \"duration\",\n",
    "                \"options\" : {\n",
    "                    \"durationFormat\" : \"h:mm\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Franja Horaria\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Día de la Semana\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Mes\",\n",
    "                \"type\" : \"singleLineText\",\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Trimestre\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Municipio\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Provincia\",\n",
    "                \"type\" : \"singleLineText\"\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Longitud\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 8\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\" : \"Latitud\",\n",
    "                \"type\" : \"number\",\n",
    "                \"options\" : {\n",
    "                    \"precision\" : 8\n",
    "                }\n",
    "            }            \n",
    "        ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se realiza el request de creación de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_crea_tabla = f\"https://api.airtable.com/v0/meta/bases/{BASE_ID}/tables\"\n",
    "    \n",
    "response = requests.post(url = endpoint_crea_tabla, json= nombres_columnas, headers = headers)\n",
    "\n",
    "print(f\"endpoint: {response.url}\")\n",
    "# print(f\"response: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"-\"*60)\n",
    "    print(\"Tabla creada con éxito. ID: \", end=\"\")\n",
    "    pprint(response.json()[\"id\"], sort_dicts = False)\n",
    "    print(\"Nombre tabla: \", end=\"\")\n",
    "    pprint(response.json()[\"name\"], sort_dicts = False)\n",
    "    print(\"-\"*60)\n",
    "else:\n",
    "    print(f\"Error en la creación de tabla. Response status code: {response.status_code}\")\n",
    "\n",
    "# Se obtiene el ID de la tabla recién creada\n",
    "try:\n",
    "    TABLE_ID = response.json()[\"id\"]\n",
    "except:\n",
    "    print(f\"No se puede obtener el ID de la tabla Meneame_{año} porque ya existe una tabla con ese nombre.\")\n",
    "    # Se utiliza el nombre de la tabla como identificador\n",
    "    TABLE_ID = f\"Meneame_{año}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se realiza el bucle de carga a Airtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Endpoint con la base definida y el ID de la tabla obtenido al momento de la creación\n",
    "endpoint = f\"{airtable_base_url}/{BASE_ID}/{TABLE_ID}\"\n",
    "\n",
    "datos_json = [{\"fields\" : df.iloc[i, :].to_dict()} for i in range(df.shape[0])]\n",
    "errores = {\"Numero\" : 0, \"Bloques\" : []}\n",
    "\n",
    "print (\"-\" *36)    \n",
    "print(f\" Total de registros a cargar: {df.shape[0]}\")\n",
    "print (\"-\" *36)\n",
    "\n",
    "for i in range(0, df.shape[0], 10):\n",
    "    data = {\"records\" : datos_json[i : i + 10],\n",
    "            \"typecast\": True}\n",
    "    \n",
    "    response = requests.post(url = endpoint, json = data, headers = headers)    \n",
    "    print(f\" Bloque de registros del {i}     al {i+10 if i+10 < df.shape[0] else i+(df.shape[0] - i)}      => Response status code: {response.status_code}\", end=\"\\r\")\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        errores[\"Numero\"] += 1\n",
    "        errores[\"Bloques\"].append(f\"Índices de {i} a {i+10}\")\n",
    "\n",
    "if errores[\"Numero\"] > 0:\n",
    "    print (\"\\n\")\n",
    "    print (\"-\" *39)    \n",
    "    print(f\" Ha habido {errores['Numero']} errores en la carga\")\n",
    "    for i in range(len(errores[\"Bloques\"])):\n",
    "        print(errores[\"Bloques\"][i])\n",
    "    print (\"-\" *39)\n",
    "else:\n",
    "    print (\"\\n\")\n",
    "    print (\"-\" *25)    \n",
    "    print(f\" Sin errores en la carga\")\n",
    "    print (\"-\" *25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descarga desde AirTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se descargan los registros\n",
    "params = {\"offset\" : None}\n",
    "endpoint = f\"{airtable_base_url}/{BASE_ID}/{TABLE_ID}\"\n",
    "\n",
    "df_airtable = pd.DataFrame()\n",
    "contador_descarga = 0\n",
    "while params.get(\"offset\") != None or df_airtable.shape[0] == 0:\n",
    "    response = requests.get(url = endpoint, headers = headers, params = params)    \n",
    "    print(f\" Bloque descarga de {contador_descarga}     a {contador_descarga + 100}     : Response: {response.status_code} => URL: {response.url}\", end=\"\\r\")\n",
    "    contador_descarga += 100\n",
    "    params[\"offset\"] = response.json().get(\"offset\")\n",
    "    \n",
    "    df_airtable = pd.concat([df_airtable, pd.json_normalize(response.json()[\"records\"])], ignore_index = True)    \n",
    "    \n",
    "    if df_airtable.shape[0] == 0:\n",
    "        print(\"\\n\")\n",
    "        print (\"-\" *39)   \n",
    "        print(f\" No existen registros para descargar\")\n",
    "        print (\"-\" *39)\n",
    "        break\n",
    "\n",
    "if df_airtable.shape[0] != 0:\n",
    "    df_airtable.columns = [x.split(\".\")[1] if \".\" in x else x for x in df_airtable.columns]\n",
    "    df_airtable.drop([\"id\", \"createdTime\"], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print (\"-\" *39)    \n",
    "print(f\" Total de registros descargados: {df_airtable.shape[0]}\")\n",
    "print (\"-\" *39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airtable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import folium\n",
    "from folium import plugins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nube de palabras con los medios más enviados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_medios_mask = np.array(Image.open(\"Data/newspaper.png\"))\n",
    "\n",
    "df_Medios = pd.DataFrame(columns=[\"Medio\"], data=df[\"Medio\"])\n",
    "df_Medios[\"Medio\"] = df_Medios[\"Medio\"].apply(lambda x : x.rsplit(\".\", maxsplit=1)[0])\n",
    "\n",
    "Medios_WordCloud = WordCloud(background_color = \"white\",\n",
    "                  max_words        = 1000,\n",
    "                  mask             = news_medios_mask,\n",
    "                  contour_width    = 10,\n",
    "                  colormap        = \"magma\",\n",
    "                  contour_color    = \"black\")\n",
    "\n",
    "Medios_WordCloud.generate(df_Medios[\"Medio\"].to_csv(header=None, index=None))\n",
    "\n",
    "plt.subplots(figsize = (50, 50))\n",
    "\n",
    "plt.imshow(Medios_WordCloud, interpolation =\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de meneos por comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data_frame=df_airtable,\n",
    "             x=\"Comunidad\",\n",
    "             color=\"Comunidad\",\n",
    "             text_auto=True,\n",
    "             title=\"Meneos por Comunidad\"\n",
    "             )\n",
    "\n",
    "fig.update_xaxes(categoryorder = \"total descending\")\n",
    "fig.update_traces(textposition = \"outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de meneos por medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cant_medio = df_airtable.groupby(\"Medio\", as_index=False).count().sort_values(\"Titular\", ascending=False)[[\"Medio\",\"Titular\"]].head()\n",
    "df_cant_medio.rename(columns={\"Titular\":\"Número Noticias\"}, inplace=True)\n",
    "\n",
    "fig = px.bar(df_cant_medio,\n",
    "             x=\"Medio\",\n",
    "             y=\"Número Noticias\",\n",
    "             color=\"Medio\",\n",
    "             text_auto=True\n",
    "             )\n",
    "fig.update_traces(textposition = \"outside\")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay entre fecha de envío y fecha de publicación por día de la semana y franja horaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_airtable[\"Delay(h)\"] = df_airtable[\"Delay\"]/3600\n",
    "df_Dia_Franja_Delay = df_airtable[[\"Día de la Semana\", \"Franja Horaria\", \"Delay(h)\"]].groupby([\"Día de la Semana\", \"Franja Horaria\"], as_index=False).mean(numeric_only=True).round(2)\n",
    "\n",
    "fig = px.sunburst(df_Dia_Franja_Delay, path=['Día de la Semana', 'Franja Horaria'], values='Delay(h)', color='Franja Horaria')\n",
    "\n",
    "fig.update_traces(textinfo = \"label+percent parent\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usuarios con más meneos acumulados por medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.treemap(data_frame       = df_airtable,\n",
    "           values           = \"Meneos\",\n",
    "           path             = [\"Medio\", \"Usuario\"]\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre la interactividad en cáda Comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interactividad = df_airtable.drop([\"Titular\",\"Entradilla\", \"Usuario\", \"Medio\", \"URL\", \"Enviado\", \"Publicado\", \"Delay\", \"Franja Horaria\", \"Día de la Semana\", \"Mes\", \"Trimestre\", \"Municipio\", \"Provincia\", \"Longitud\", \"Latitud\"], axis = 1)\n",
    "df_interactividad[\"Votos\"]= df_interactividad[\"Positivos\"] +df_interactividad[\"Anonimos\"] + df_interactividad[\"Negativos\"]\n",
    "df_interactividad = df_interactividad.groupby(\"Comunidad\", as_index = False).mean().round()\n",
    "\n",
    "\n",
    "comunidad = df_interactividad[\"Comunidad\"]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Clicks', x=comunidad, y=df_interactividad[\"Clicks\"]),\n",
    "    go.Bar(name='Votos', x=comunidad, y=df_interactividad[\"Votos\"]),\n",
    "    go.Bar(name='Comentarios', x=comunidad, y=df_interactividad[\"Comentarios\"]),\n",
    "    go.Bar(name='Karma', x=comunidad, y=df_interactividad[\"Karma\"]),\n",
    "])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa con el número de meneos por municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapas = df_airtable[df_airtable[\"Longitud\"] != 0]\n",
    "mapa = folium.Map(location = [40.4637, -3.7492], zoom_start = 6, tiles = \"CartoDB Positron\") # Inicializamos un mapa de España\n",
    "\n",
    "incidents = plugins.MarkerCluster() # Creamos una instancia de un objeto de cluster de marca para los incidentes en el marco de datos\n",
    "\n",
    "for lat, lng, label, URL in zip(df_mapas[\"Latitud\"], df_mapas[\"Longitud\"], df_mapas[\"Titular\"], df_mapas[\"URL\"]):\n",
    "\n",
    "    popup = label + \"\\n\" + \"<a target = \\\"_blank\\\" href =\\\"\" + URL + \"\\\">Ctrl+click</a>\"        # creamos nuestro mapa\n",
    "\n",
    "    incidents.add_child(folium.Marker(location = [lat, lng],\n",
    "                                      icon     = folium.Icon(icon          = \"fa-newspaper\",\n",
    "                                                             icon_color    = \"white\",\n",
    "                                                             color         = \"orange\",\n",
    "                                                             prefix        = \"fa\"),\n",
    "                                      popup    = popup))\n",
    "    \n",
    "mapa.add_child(incidents)\n",
    "\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapa coroplético con los meneos por provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provincias = df_mapas.loc[:,[\"Titular\", \"Provincia\"]].groupby(\"Provincia\", as_index = False).count()\n",
    "df_provincias.rename(columns={\"Titular\" : \"Número noticias\"}, inplace=True)\n",
    "\n",
    "españa_geo = \"Data/provincias-espanolas.geojson\" # cargamos GeoJson con los límites geográficos de las provincias de España\n",
    "\n",
    "mapa = folium.Map(location = [40.4637, -3.7492], zoom_start = 6, tiles = \"CartoDB Positron\") # Inicializamos un mapa de España\n",
    "\n",
    "folium.Choropleth(geo_data = españa_geo,            # creamos nuestro mapa\n",
    "                  data     = df_provincias,\n",
    "                  columns  = [\"Provincia\", \"Número noticias\"],\n",
    "                  legend_name = \"Número de noticias\",\n",
    "                  legend_scale = \"50\",\n",
    "                  fill_color = \"Oranges\",\n",
    "                  fill_opacity = 0.8,\n",
    "                  line_opaci100ty = 0.1,\n",
    "                  line_weight = 0.2,\n",
    "                  bins = 100,\n",
    "                  key_on   = \"feature.properties.provincia\").add_to(mapa)\n",
    "\n",
    "mapa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
